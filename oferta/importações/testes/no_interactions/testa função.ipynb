{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "32400a3b-c480-4c21-858f-958501eed2cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['UREIA_k', 'MOP_k']\n",
      "['MAP_k', 'SAM_k']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>nick</th>\n",
       "      <th>SG_UF_NCM</th>\n",
       "      <th>oc</th>\n",
       "      <th>oc_pred</th>\n",
       "      <th>KG_LIQUIDO</th>\n",
       "      <th>kg_pred</th>\n",
       "      <th>pt_pred_real</th>\n",
       "      <th>md_c</th>\n",
       "      <th>md_r</th>\n",
       "      <th>d</th>\n",
       "      <th>y_active</th>\n",
       "      <th>anos_inclu</th>\n",
       "      <th>uf_list</th>\n",
       "      <th>nick_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1711929600000000000</td>\n",
       "      <td>MOP_k</td>\n",
       "      <td>BA</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>285641408.0</td>\n",
       "      <td>3.400391e+08</td>\n",
       "      <td>119</td>\n",
       "      <td>None_</td>\n",
       "      <td>None_</td>\n",
       "      <td>0 days</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>['BA']</td>\n",
       "      <td>['MAP_k', 'SAM_k']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1711929600000000000</td>\n",
       "      <td>UREIA_k</td>\n",
       "      <td>BA</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>197687096.0</td>\n",
       "      <td>1.958509e+08</td>\n",
       "      <td>99</td>\n",
       "      <td>None_</td>\n",
       "      <td>None_</td>\n",
       "      <td>0 days</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>['BA']</td>\n",
       "      <td>['MAP_k', 'SAM_k']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date     nick SG_UF_NCM  oc  oc_pred   KG_LIQUIDO  \\\n",
       "0  1711929600000000000    MOP_k        BA   1        1  285641408.0   \n",
       "1  1711929600000000000  UREIA_k        BA   1        1  197687096.0   \n",
       "\n",
       "        kg_pred  pt_pred_real   md_c   md_r      d  y_active  anos_inclu  \\\n",
       "0  3.400391e+08           119  None_  None_ 0 days         5           6   \n",
       "1  1.958509e+08            99  None_  None_ 0 days         5           6   \n",
       "\n",
       "  uf_list           nick_list  \n",
       "0  ['BA']  ['MAP_k', 'SAM_k']  \n",
       "1  ['BA']  ['MAP_k', 'SAM_k']  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC_\n",
    "from sklearn.ensemble import RandomForestRegressor as RFR_\n",
    "from sklearn import metrics\n",
    "\n",
    "import datetime\n",
    "\n",
    "w=0\n",
    "\n",
    "md_c=None\n",
    "md_r=None\n",
    "d=datetime.timedelta(365.25*0)\n",
    "y_active=5\n",
    "max_anos=5\n",
    "min_anos=5\n",
    "\n",
    "imp_fert=pd.read_csv('~/git/BD/temp/imp_fert_quanti.csv')\n",
    "\n",
    "# Seleciona UF e nick\n",
    "uf_list=['BA']\n",
    "nick_list_list=[['UREIA_k','MOP_k'],['MAP_k','SAM_k']]\n",
    "\n",
    "\n",
    "# Inicia df para coletar resultados de classificação e regressão do loop\n",
    "q=pd.DataFrame()\n",
    "r=pd.DataFrame()\n",
    "\n",
    "# Inicia loop sobre as listas de nick\n",
    "for nick_list in nick_list_list:\n",
    "\n",
    "    print(nick_list)\n",
    "    \n",
    "    # Filtra nick listados\n",
    "    imp_fert_t=imp_fert[(imp_fert.SG_UF_NCM.astype(str).isin(uf_list))&(imp_fert.nick.astype(str).isin(nick_list))]\n",
    "\n",
    "    # Acerta as tipo das colunas categóricas\n",
    "    imp_fert_t[['CO_MES','nick','SG_UF_NCM','CO_PAIS','CO_URF']]=imp_fert_t[['CO_MES','nick','SG_UF_NCM','CO_PAIS','CO_URF']].astype('category')\n",
    "\n",
    "    '''Descartra colunas com apenas conteúdo único\n",
    "    if len(imp_fert_t.SG_UF_NCM.unique())==1:\n",
    "        imp_fert_t.drop(columns='SG_UF_NCM',inplace=True)\n",
    "    if len(imp_fert_t.nick.unique())==1:\n",
    "        imp_fert_t.drop(columns='nick',inplace=True)'''\n",
    "\n",
    "    # Inicia loop sobre as datas\n",
    "    imp_fert_t['date']=pd.to_datetime(imp_fert_t.CO_ANO.astype(str)+'/'+imp_fert_t.CO_MES.astype(str)+'/1')\n",
    "    date=(imp_fert_t.date.max()-d).floor('d')\n",
    "    \n",
    "    # Filtra deixando passar registros menores ou iguais a data do loop\n",
    "    imp_fert_t2=imp_fert_t[(imp_fert_t.date<=date)]\n",
    "    \n",
    "    # Filtra categorias ativas\n",
    "    imp_fert_t2['date']=pd.to_datetime(imp_fert_t2.CO_ANO.astype(str)+'/'+imp_fert_t2.CO_MES.astype(str)+'/1')\n",
    "    fim=imp_fert_t2.date.max()\n",
    "    ini=pd.date_range(end=fim,periods=12*y_active,freq='MS')[0]\n",
    "    filtra_atividade=imp_fert_t2[imp_fert_t2.date>=ini][imp_fert_t2.select_dtypes(include='category').columns.tolist()].drop_duplicates()\n",
    "    imp_fert_t2=filtra_atividade.merge(imp_fert_t2)\n",
    "    \n",
    "    '''# Limita comprimento do estudo em anos\n",
    "    ini=pd.date_range(end=fim,periods=12*anos_inclu,freq='MS')[0]\n",
    "    imp_fert_t2=imp_fert_t2[(imp_fert_t2.date>=ini)]\n",
    "    \n",
    "    print('\\n',ini,'\\n',(imp_fert_t2.date.max()-imp_fert_t2.date.min()).days/365.25)'''\n",
    "    \n",
    "    # Confere comprimento mínimo\n",
    "    if (imp_fert_t2.date.max()-imp_fert_t2.date.min()).days/365.25>anos_inclu:\n",
    "        \n",
    "        ################## Produz a Matriz Esparsa ###########\n",
    "        # salva datas de início e fim\n",
    "        ini=imp_fert_t2.date.min()\n",
    "        fim=imp_fert_t2.date.max()\n",
    "        # Cria conjunto de anos\n",
    "        anos_df=pd.DataFrame({'CO_ANO':np.arange(ini.year,fim.year+1)}).assign(key=0)\n",
    "        \n",
    "        # Funde anos e categorias (inclusive mês) criando nova tabela ms\n",
    "        # Note que aqui conjunto de carac que não ocorra em determinado mês não é criado com zero quant. para dar velocidade de processamento\n",
    "        imp_fert_t2_ms=anos_df.merge(\\\n",
    "            imp_fert_t2[imp_fert_t2.select_dtypes('category').columns.tolist()].assign(key=0).drop_duplicates(),how='outer'\n",
    "        ).drop(columns='key')\n",
    "        \n",
    "        # liminta matriz a datas reais existentes\n",
    "        imp_fert_t2_ms['date']=pd.to_datetime(imp_fert_t2_ms.CO_ANO.astype(str)+'/'+imp_fert_t2_ms.CO_MES.astype(str)+'/1')\n",
    "        imp_fert_t2_ms=imp_fert_t2_ms[(imp_fert_t2_ms.date>=ini)&(imp_fert_t2_ms.date<=fim)]\n",
    "        # funde ms e imp_fert\n",
    "        imp_fert_t2=imp_fert_t2_ms.merge(imp_fert_t2,how='outer')\n",
    "        imp_fert_t2['KG_LIQUIDO']=imp_fert_t2[['KG_LIQUIDO']].fillna(0)\n",
    "        \n",
    "        ###############################################################################################################\n",
    "        \n",
    "        # Diferencia ocorrências reais de não ocorrência\n",
    "        imp_fert_t2=imp_fert_t2.assign(oc=0)\n",
    "        imp_fert_t2.loc[imp_fert_t2.KG_LIQUIDO>0,'oc']=1\n",
    "        \n",
    "        # Parametriza os algoritmos\n",
    "        RFC=RFC_(max_depth=md_c)\n",
    "        RFR=RFR_(max_depth=md_r)\n",
    "        \n",
    "        # Adequa medidas de tempo para os algoritmos\n",
    "        imp_fert_t2.date=imp_fert_t2.date.astype(int)\n",
    "        imp_fert_t2.drop(columns='CO_ANO',inplace=True)\n",
    "\n",
    "        # Transforma categoricos em dummies\n",
    "        imp_fert_dumm=pd.get_dummies(imp_fert_t2,prefix_sep='~')\n",
    "\n",
    "        # Identifica registros para treino e teste\n",
    "        train_dumm=imp_fert_dumm[imp_fert_dumm.date< imp_fert_dumm.date.max()]\n",
    "        test_dumm =imp_fert_dumm[imp_fert_dumm.date==imp_fert_dumm.date.max()]\n",
    "\n",
    "        # inicia loop de repetição (para teste de variação dos algorítmos randômicos)\n",
    "        for x in range(2):\n",
    "\n",
    "            # ******* CLASSIFCAÇÃO *******\n",
    "            # Identifica X e y classifier\n",
    "            X_train_c=train_dumm.drop(columns=['KG_LIQUIDO','oc'])\n",
    "            y_train_c=train_dumm.oc\n",
    "            X_test_c =test_dumm.drop(columns=['KG_LIQUIDO','oc'])\n",
    "            y_test_c =test_dumm.oc\n",
    "            # Fit classifier\n",
    "            RFC.fit(X_train_c,y_train_c)\n",
    "            # Predict classifier\n",
    "            test_pred_c=X_test_c.assign(oc_pred=RFC.predict(X_test_c)).assign(oc=y_test_c)\n",
    "            # Armazena\n",
    "            q=pd.concat([q,test_pred_c])\n",
    "            \n",
    "            \n",
    "            # ******* REGRESSÃO *******\n",
    "            # Filtra deixando passar registros ocorridos\n",
    "            imp_fert_t2=imp_fert_t2[imp_fert_t2.oc==1]\n",
    "            \n",
    "            # verifica o comprimento mínimo do tempo de estudo\n",
    "            if len(imp_fert_t2[imp_fert_t2.date.astype('datetime64[ns]')==date])>1:\n",
    "\n",
    "                # Transforma categoricos em dummies\n",
    "                imp_fert_dumm=pd.get_dummies(imp_fert_t2,prefix_sep='~')\n",
    "                \n",
    "                # Identifica registros para treino e teste\n",
    "                train_dumm=imp_fert_dumm[imp_fert_dumm.date< imp_fert_dumm.date.max()]\n",
    "                test_dumm =imp_fert_dumm[imp_fert_dumm.date==imp_fert_dumm.date.max()]\n",
    "            \n",
    "                # Identifica X e y\n",
    "                X_train_r=train_dumm.drop(columns=['KG_LIQUIDO','oc'])\n",
    "                y_train_r=train_dumm.KG_LIQUIDO\n",
    "                \n",
    "                X_test_r =test_dumm.drop(columns=['KG_LIQUIDO','oc'])\n",
    "                y_test_r =test_dumm.KG_LIQUIDO\n",
    "                \n",
    "                # Fit regressor\n",
    "                RFR.fit(X_train_r,y_train_r)\n",
    "                \n",
    "                # Predict classifier\n",
    "                test_pred_r=X_test_r.assign(kg_pred=RFR.predict(X_test_r)).assign(KG_LIQUIDO=y_test_r)\n",
    "\n",
    "                \n",
    "                r=pd.concat([r,test_pred_r])\n",
    "                \n",
    "\n",
    "\n",
    "\n",
    "    def f_dumm(df_dumm):\n",
    "        '''Retorna dumm para original'''\n",
    "        a=pd.from_dummies(df_dumm.select_dtypes(include='bool'),sep='~')\n",
    "        b=df_dumm.select_dtypes(exclude='bool')\n",
    "        c=pd.concat([a,b],axis=1)\n",
    "        return c\n",
    "    q=f_dumm(q)\n",
    "    r=f_dumm(r)\n",
    "    \n",
    "    score=q.merge(r,how='outer')\n",
    "    \n",
    "    g_list=['date','nick','SG_UF_NCM']\n",
    "    \n",
    "    g=[x for x in g_list if x in score.columns]\n",
    "    \n",
    "    score=score.groupby(by=g)[['oc','oc_pred','KG_LIQUIDO','kg_pred']].sum().reset_index()\n",
    "    \n",
    "    score.loc[score.oc>1,'oc']=1\n",
    "    score.loc[score.oc_pred>1,'oc_pred']=1\n",
    "    \n",
    "    score_r=score[(score.oc==1)&(score.oc_pred==1)]\n",
    "    score_r=score_r.assign(pt_pred_real=(score_r.kg_pred/score_r.KG_LIQUIDO*100).astype(int))\\\n",
    "    .assign(md_c=str(md_c)+'_').assign(md_r=str(md_r)+'_').assign(d=datetime.timedelta(365.25*0)).assign(y_active=5).assign(anos_inclu=6)\\\n",
    "    .assign(uf_list=str(uf_list)).assign(nick_list=str(nick_list))\n",
    "    \n",
    "    \n",
    "    if w==0:\n",
    "        score_rb=score_r\n",
    "        w==1\n",
    "    else:\n",
    "        score_rb=pd.concat([score_r,score_rb])\n",
    "\n",
    "score_rb.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbe536d-3d91-4db2-ae40-4ac7cede9551",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
