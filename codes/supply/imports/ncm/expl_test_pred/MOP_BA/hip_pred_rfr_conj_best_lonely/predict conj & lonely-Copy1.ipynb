{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d0e2c40-5656-4aa5-9e50-0c23aa4a6d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "ini=time.time()\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.tseries.offsets import DateOffset\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "imp_fert=pd.read_csv('/home/andre301267/git/Pricing-Fertilizer/DB/temp/imp_fert_ncm_quanti.csv')\n",
    "\n",
    "exp_soja=pd.read_csv('/home/andre301267/git/Pricing-Fertilizer/DB/temp/exp_soja_ncm_quanti.csv')\n",
    "\n",
    "comex_df=pd.concat([imp_fert,exp_soja]).sort_values(by=['year','month'])\\\n",
    ".drop(columns=['US$_freight','US$_insurance','cif_kg','fob_kg','preço'])\n",
    "\n",
    "# filtra km deixando passar o maior km de cada produto\n",
    "filtra_km=comex_df[['Product','km']].drop_duplicates().sort_values(by=['Product','km'],ascending=False)\\\n",
    "    .drop_duplicates(subset='Product')\n",
    "comex_df=comex_df.merge(filtra_km)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "444f7423-6a33-46a7-89d3-ea660c168ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "comex_df['date']=pd.to_datetime(comex_df.year.astype(str)+'-'+comex_df.month.astype(str)+'-01')\n",
    "comex_df0=comex_df[comex_df.date<=comex_df.date.max()-DateOffset(months=11)]\n",
    "comex_df0=comex_df0.drop(columns=['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cbd54bde-dff8-4f7a-945c-9d24f77a9071",
   "metadata": {},
   "outputs": [],
   "source": [
    "year_testing=10\n",
    "prdt_foco='MOP'\n",
    "uf_foco='BA'\n",
    "month_foco=comex_df0[comex_df0.year==comex_df0.year.max()].month.max()\n",
    "# Parameters for lonely processing\n",
    "prdt_lonely=[prdt_foco]\n",
    "uf_lonely=[uf_foco]\n",
    "month_lonely=[month_foco]\n",
    "# Parameters for joint processing\n",
    "prdt_conj=[prdt_foco]+['MAP','Soy Group']\n",
    "uf_conj=[uf_foco]+['GO']\n",
    "m_ext=3\n",
    "max_depth=None\n",
    "max_features=None\n",
    "degree=1\n",
    "hip_list = ['lonely','conj']\n",
    "\n",
    "m_ini=month_foco-m_ext\n",
    "month_conj=np.arange(m_ini,month_foco+1)\n",
    "month_conj[month_conj<=0]+=12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b8721fc-f57c-430d-a642-9eb110395456",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " lonely\n",
      "\n",
      "Para lonely - rse = 32 Kton\n",
      "\n",
      " conj\n",
      "\n",
      "Para conj - rse = 25 Kton\n",
      "Duração: 0.2 minutos.\n"
     ]
    }
   ],
   "source": [
    "# TESTE\n",
    "\n",
    "dict={'lonely':[prdt_lonely, uf_lonely, month_lonely],\n",
    "      'conj'  :[prdt_conj  , uf_conj,   month_conj]}\n",
    "\n",
    "comex_df1=comex_df0.copy()\n",
    "# Save real begins and ends\n",
    "comex_df1['date']=pd.to_datetime(comex_df1.year.astype(str)+'-'+comex_df1.month.astype(str)+'-01')\n",
    "date_min=comex_df1.date.min()\n",
    "date_max=comex_df1.date.max()\n",
    "\n",
    "# Calendar full\n",
    "years=pd.DataFrame({'year':np.arange(comex_df1.year.min(),\n",
    "                                     comex_df1.year.max()+1)}).assign(key=0)\n",
    "months=pd.DataFrame({'month':np.arange(1,13)}).assign(key=0)\n",
    "calendar=years.merge(months,on='key')\n",
    "calendar_full=comex_df1[['Product','UF']].drop_duplicates().assign(key=0).merge(calendar,on='key').drop('key',axis=1)\n",
    "\n",
    "# Merge calendar full\n",
    "comex_df1=comex_df1.merge(calendar_full)\n",
    "\n",
    "# Saprse Matrix\n",
    "comex_df1[['month','Product','UF']]=comex_df1[['month', 'Product','UF']].astype('category')\n",
    "comex_df1=comex_df1.groupby(by=['year','month','Product','UF'],observed=False)[[x for x in ['US$_fob','kg'] if x in comex_df1.columns]].sum().reset_index()\n",
    "\n",
    "# Prune\n",
    "comex_df1['date']=pd.to_datetime(comex_df1.year.astype(str)+'-'+comex_df1.month.astype(str)+'-01')\n",
    "comex_df1=comex_df1[(comex_df1.date>=date_min)&(comex_df1.date<=date_max)]\n",
    "\n",
    "qq=pd.DataFrame()\n",
    "\n",
    "for f in hip_list:\n",
    "\n",
    "    h=dict[f]\n",
    "\n",
    "    # Filtra Product, UF and month\n",
    "    comex_df_t1=comex_df1[\n",
    "    (comex_df1.Product.isin(h[0]))&\n",
    "    (comex_df1.UF.isin(h[1]))&\n",
    "    (comex_df1.month.isin(h[2]))].copy()\n",
    "\n",
    "    comex_df_t1.drop(columns='US$_fob',inplace=True)\n",
    "\n",
    "    \n",
    "    # Dummies\n",
    "    comex_df_t1=pd.get_dummies(comex_df_t1,prefix_sep='~')\n",
    "\n",
    "    # Classify\n",
    "    \n",
    "    comex_df_t1=comex_df_t1.assign(oc=0)\n",
    "    comex_df_t1.loc[comex_df_t1.kg>0,'oc']=1\n",
    "    \n",
    "    comex_df_t2=comex_df_t1.copy()\n",
    "\n",
    "    \n",
    "    for r in range(1,year_testing+1):\n",
    "        \n",
    "        # Classifying\n",
    "        train=comex_df_t2[comex_df_t2.date<comex_df_t2.date.max()]\n",
    "        test=comex_df_t2[comex_df_t2.date==comex_df_t2.date.max()]\n",
    "\n",
    "        train.date=train.date.astype(int)\n",
    "        test.date=test.date.astype(int)\n",
    "    \n",
    "        X_train=train.drop(['kg','oc'],axis=1)\n",
    "\n",
    "        y_train=train.oc\n",
    "        X_test=test.drop(['kg','oc'],axis=1)\n",
    "        \n",
    "        y_test=test.oc\n",
    "        \n",
    "        from sklearn.ensemble import RandomForestClassifier as rfc\n",
    "        \n",
    "        model=rfc()\n",
    "        \n",
    "        model.fit(X_train,y_train)\n",
    "        test['y_pred']=model.predict(X_test)\n",
    "\n",
    "        test.date=test.date.astype('datetime64[ns]')\n",
    "        \n",
    "        if r==1:\n",
    "            results=test\n",
    "        else:\n",
    "            results=pd.concat([results,test])\n",
    "\n",
    "        comex_df_t2=comex_df_t2[comex_df_t2.date<=comex_df_t2.date.max()-DateOffset(years=1)]\n",
    "\n",
    "    # Regression\n",
    "    \n",
    "    comex_df_t1=results.merge(comex_df_t1,how='outer')\n",
    "        \n",
    "    comex_df_t1=comex_df_t1[(comex_df_t1.oc==1)&(comex_df_t1.y_pred.isin([1,np.nan]))].drop(columns='y_pred')\n",
    "\n",
    "    comex_df_t2=comex_df_t1.copy()\n",
    "    \n",
    "    features_df=pd.DataFrame()\n",
    "    \n",
    "    for r in range(1,year_testing+1):\n",
    "        #print('f',f)\n",
    "        #print('r',r)\n",
    "        \n",
    "        train=comex_df_t2[comex_df_t2.date<comex_df_t2.date.max()]\n",
    "        test=comex_df_t2[comex_df_t2.date==comex_df_t2.date.max()]\n",
    "\n",
    "        train.date=train.date.astype(int)\n",
    "        test.date=test.date.astype(int)\n",
    "    \n",
    "          \n",
    "        if f == 'conj':\n",
    "            from sklearn.ensemble import RandomForestRegressor as model\n",
    "            model=model(max_depth=max_depth,max_features=max_features)\n",
    "        else:\n",
    "            from sklearn.linear_model import LinearRegression\n",
    "            from sklearn.preprocessing import PolynomialFeatures\n",
    "            from sklearn.pipeline import make_pipeline\n",
    "            polynomial_features = PolynomialFeatures(degree=degree)\n",
    "            linear_regression = LinearRegression()\n",
    "            model = make_pipeline(polynomial_features, linear_regression)\n",
    "\n",
    "            \n",
    "\n",
    "        X_train=train.drop(['kg','oc'],axis=1)\n",
    "        y_train=train.kg\n",
    "        \n",
    "        X_test=test.drop(['kg','oc'],axis=1)\n",
    "        y_test=test.kg\n",
    "\n",
    "        #print('\\ntrain:',train.year.unique(),'\\ntest:',test.year.unique())\n",
    "        \n",
    "        \n",
    "        model.fit(X_train,y_train)\n",
    "        test['y_pred']=y_pred=model.predict(X_test)\n",
    "\n",
    "        \n",
    "        if r==1:\n",
    "            results=test\n",
    "        else:\n",
    "            results=pd.concat([results,test])\n",
    "\n",
    "        qq=pd.concat([qq,results.assign(f=f)])\n",
    "        \n",
    "        comex_df_t2=comex_df_t2[comex_df_t2.date<=comex_df_t2.date.max()-DateOffset(years=1)]\n",
    "    \n",
    "    print('\\n',f)\n",
    "    \n",
    "    # Back from dummies\n",
    "    o=results[results.columns[~results.columns.str.contains('~')]]    \n",
    "    prdt=pd.from_dummies(results[results.columns[results.columns.str.contains('Product')]],sep='~')    \n",
    "    month=pd.from_dummies(results[results.columns[results.columns.str.contains('month')]],sep='~')    \n",
    "    uf=pd.from_dummies(results[results.columns[results.columns.str.contains('UF')]],sep='~')    \n",
    "    results=pd.concat([o,prdt,month,uf],axis=1)\n",
    "\n",
    "    # Filtering\n",
    "    mes=results.month.unique()[0]    \n",
    "    results=results[(results.Product=='MOP')&(results.month==mes)&(results.UF=='BA')]\n",
    "\n",
    "    # Metrics\n",
    "    from sklearn.metrics import root_mean_squared_error as rse\n",
    "    results['rse']=rse(results.kg,results.y_pred)    \n",
    "    print(f\"\\nPara {f} - rse = {int(results.rse.unique()/10**6)} Kton\")\n",
    "    \n",
    "\n",
    "end=time.time()\n",
    "\n",
    "print(f\"Duração: {round((end-ini)/60,1)} minutos.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6fe3159-ac8a-4095-a8a6-da0abc1507e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5af689a6-a3f5-4bda-97a7-6faffc0210d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREDIÇÃO\n",
    "\n",
    "# Save real begins and ends\n",
    "comex_df['date']=pd.to_datetime(comex_df.year.astype(str)+'-'+comex_df.month.astype(str)+'-01')\n",
    "date_min=comex_df.date.min()\n",
    "date_max=comex_df.date.max()\n",
    "\n",
    "# Calendar full\n",
    "years=pd.DataFrame({'year':np.arange(comex_df.year.min(),\n",
    "                                     comex_df.year.max()+1)}).assign(key=0)\n",
    "months=pd.DataFrame({'month':np.arange(1,13)}).assign(key=0)\n",
    "calendar=years.merge(months,on='key')\n",
    "calendar_full=comex_df[['Product','UF']].drop_duplicates().assign(key=0).merge(calendar,on='key').drop('key',axis=1)\n",
    "\n",
    "# Merge calendar full\n",
    "comex_df=comex_df.merge(calendar_full)\n",
    "\n",
    "# Saprse Matrix\n",
    "comex_df[['month','Product','UF']]=comex_df[['month', 'Product','UF']].astype('category')\n",
    "comex_df=comex_df1.groupby(by=['year','month','Product','UF'],observed=False)[[x for x in ['US$_fob','kg'] if x in comex_df1.columns]]\\\n",
    ".sum().reset_index()\n",
    "\n",
    "# Prune\n",
    "comex_df['date']=pd.to_datetime(comex_df.year.astype(str)+'-'+comex_df.month.astype(str)+'-01')\n",
    "comex_df=comex_df[(comex_df.date>=date_min)&(comex_df.date<=date_max)]\n",
    "\n",
    "qq=pd.DataFrame()\n",
    "\n",
    "# Filtra Product, UF and month\n",
    "comex_df=comex_df[\n",
    "(comex_df.Product.isin(h[0]))&\n",
    "(comex_df.UF.isin(h[1]))&\n",
    "(comex_df.month.isin(h[2]))].copy()\n",
    "\n",
    "comex_df.drop(columns='US$_fob',inplace=True)\n",
    "\n",
    "# Dummies\n",
    "comex_df=pd.get_dummies(comex_df,prefix_sep='~')\n",
    "\n",
    "# Classify\n",
    "comex_df=comex_df.assign(oc=0)\n",
    "comex_df.loc[comex_df.kg>0,'oc']=1\n",
    "\n",
    "# Classifying\n",
    "train=comex_df[comex_df.date<comex_df.date.max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b028907d-0d14-4542-a8b3-08b29ade10e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ead2aeab-45e1-40f9-a215-dfa7d4788dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.date=train.date.max()+DateOffset(months=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b71f978-d3d3-42f6-9399-dc028dc518b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred[pred.columns[pred.columns.str.contains('~')]]=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d15c47a4-c3a4-44e6-8304-860705f805a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred['month~'+str(month_foco)]=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e9b733-dd3e-4354-9eab-a22a7aa89b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred['Product~'+str(prdt_foco)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ec309a3-cd10-46b1-a8b7-ce77c9eae7b8",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (62411553.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[10], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    a=\u001b[0m\n\u001b[0m      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "a="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b3a186-f81d-4776-ae39-46cbb6376825",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25591d28-c3b2-4a39-999d-5f745cb7843b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bcd6bf9-bc29-4118-8982-9e8d3a5d80b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef25a9b1-5f97-451a-aa60-9fa728f80109",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=pd.DataFrame({'date':[pred_date],'year':[pred_year],'month':[pred_month],'Product':[prdt_foco],'UF':[uf_foco]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55742461-2841-468e-a45e-c011541d0fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9a1d3d-8c40-49b5-bf1d-cdd44c7292ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "a="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c049347-daef-49db-8ceb-225d431e1312",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f99072-37a3-4523-903c-305e31d741f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4701828-9d2e-4bb3-9b4d-9a0851a31182",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5e03ca-b2e0-458b-a510-b6abbe0eda50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650085d9-069f-480e-8224-4a2aa49412f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702b99a2-6d89-458e-b5be-fbcd92ccd29a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d5a4bc-8bc8-47d9-8165-36b5b39dbc08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa6e848-27a6-4d41-9a9f-8879beb9656b",
   "metadata": {},
   "outputs": [],
   "source": [
    "A="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490186fd-1d56-4f64-9279-c2ca6a95929d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.date=train.date.astype(int)\n",
    "pred.date=pred.date.astype(int)\n",
    "\n",
    "X_train=train.drop(['kg','oc'],axis=1)\n",
    "\n",
    "y_train=train.oc\n",
    "X_pred=pred\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier as rfc\n",
    "model=rfc()\n",
    "\n",
    "model.fit(X_train,y_train)\n",
    "pred['y_pred']=model.predict(X_pred)\n",
    "\n",
    "pred.date=pred.date.astype('datetime64[ns]')\n",
    "\n",
    "# Regression\n",
    "comex_df_t1=pred.merge(comex_df_t1,how='outer')\n",
    "comex_df_t1=comex_df_t1[(comex_df_t1.oc==1)&(comex_df_t1.y_pred.isin([1,np.nan]))].drop(columns='y_pred')\n",
    "comex_df_t2=comex_df_t1.copy()\n",
    "\n",
    "train=comex_df_t2[comex_df_t2.date<comex_df_t2.date.max()]\n",
    "\n",
    "train.date=train.date.astype(int)\n",
    "pred.date=pred.date.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648b02eb-0926-43b3-8f76-e47609cf1eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "if f == 'conj':\n",
    "    from sklearn.ensemble import RandomForestRegressor as model\n",
    "    model=model(max_depth=max_depth,max_features=max_features)\n",
    "else:\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    from sklearn.preprocessing import PolynomialFeatures\n",
    "    from sklearn.pipeline import make_pipeline\n",
    "    polynomial_features = PolynomialFeatures(degree=degree)\n",
    "    linear_regression = LinearRegression()\n",
    "    model = make_pipeline(polynomial_features, linear_regression)\n",
    "\n",
    "    \n",
    "\n",
    "X_train=train.drop(['kg','oc'],axis=1)\n",
    "y_train=train.kg\n",
    "\n",
    "X_pred=pred.drop(['kg','oc'],axis=1)\n",
    "y_pred=pred.kg\n",
    "\n",
    "#print('\\ntrain:',train.year.unique(),'\\npred:',pred.year.unique())\n",
    "\n",
    "\n",
    "model.fit(X_train,y_train)\n",
    "pred['y_pred']=y_pred=model.predict(X_pred)\n",
    "\n",
    "\n",
    "if r==1:\n",
    "    pred=pred\n",
    "else:\n",
    "    pred=pd.concat([pred,pred])\n",
    "\n",
    "qq=pd.concat([qq,pred.assign(f=f)])\n",
    "\n",
    "comex_df_t2=comex_df_t2[comex_df_t2.date<=comex_df_t2.date.max()-DateOffset(years=1)]\n",
    "\n",
    "print('\\n',f)\n",
    "\n",
    "# Back from dummies\n",
    "o=pred[pred.columns[~pred.columns.str.contains('~')]]    \n",
    "prdt=pd.from_dummies(pred[pred.columns[pred.columns.str.contains('Product')]],sep='~')    \n",
    "month=pd.from_dummies(pred[pred.columns[pred.columns.str.contains('month')]],sep='~')    \n",
    "uf=pd.from_dummies(pred[pred.columns[pred.columns.str.contains('UF')]],sep='~')    \n",
    "pred=pd.concat([o,prdt,month,uf],axis=1)\n",
    "\n",
    "# Filtering\n",
    "mes=pred.month.unique()[0]    \n",
    "pred=pred[(pred.Product=='MOP')&(pred.month==mes)&(pred.UF=='BA')]\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import root_mean_squared_error as rse\n",
    "pred['rse']=rse(pred.kg,pred.y_pred)    \n",
    "print(f\"\\nPara {f} - rse = {int(pred.rse.unique()/10**6)} Kton\")\n",
    "\n",
    "\n",
    "end=time.time()\n",
    "\n",
    "print(f\"Duração: {round((end-ini)/60,1)} minutos.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf0cf63-b35d-4f2e-869c-ffc4bf7ca63f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f0ec2a-845c-4a81-ba95-9ddae5a1bd3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42774be-4479-4f1a-85cf-87ee45cb982f",
   "metadata": {},
   "outputs": [],
   "source": [
    "qq_f=qq[(qq['Product~'+prdt_foco]==1)&(qq['UF~'+uf_foco]==1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634c2f48-6554-470b-84e1-9bd85aae3158",
   "metadata": {},
   "outputs": [],
   "source": [
    "qq_l=pd.concat([\n",
    "    qq_f[qq_f.f=='conj'][['year','kg']].assign(tipo='real'),\n",
    "    qq_f[qq_f.f=='lonely'][['year','y_pred']].assign(tipo='pred_lonely').rename(columns={'y_pred':'kg'}),\n",
    "    qq_f[qq_f.f=='conj'][['year','y_pred']].assign(tipo='pred_conj').rename(columns={'y_pred':'kg'}),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22e5548-127f-49b9-8135-7f35917d0d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "g=sns.relplot(data=qq_l,x='year',y='kg',hue='tipo',height=3,aspect=4, style='tipo')\n",
    "#g.set(ylim=(3*10**7, None))\n",
    "g.fig.suptitle(f\"Imports\\nProduct: MOP* - Month: {mes} - UF: BA\\nReal and Predictions\",y=1.3)\n",
    "plt.xticks(ticks=qq_l.year.unique())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef7d6f2-059e-48a2-b9a7-845137277c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "end=time.time()\n",
    "print(f\"Duração: {round((end-ini)/60,1)} minutos.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08228331-ce03-4042-9526-fca55c73c0a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
